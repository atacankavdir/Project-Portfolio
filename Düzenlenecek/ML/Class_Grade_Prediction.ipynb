{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Grade Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary results are below, for further information; code part consists of detailed explanations.\n",
    "\n",
    "Several new functions defined with the purpose of data manipulation and feature engineering.\n",
    "\n",
    "For Q1;\n",
    "    According to given information, I defined the final score function and apply it without MT3 score.\n",
    "    So my predictor is : calculated final score\n",
    "    The target is : pass/fail condition\n",
    "    I checked distribution of the feature and the target and there is no obstacle to use this setting.\n",
    "    Decision tree classifer has been used as the predictor and the results are:\n",
    "    Class:A\n",
    "    Accuracy Score: 0.9423076923076923\n",
    "        \n",
    "    Class:B\n",
    "    Accuracy Score: 0.8571428571428571\n",
    "        \n",
    "    Class:C\n",
    "    Accuracy Score: 0.8970588235294118\n",
    "\n",
    "For Q2;\n",
    "    According to given information, I used only MT1 scores of all semesters and apply it..\n",
    "    So my predictor is : MT1 scores of prior semesters\n",
    "    The target is : pass/fail condition\n",
    "    I checked distribution of the feature and the target and there is no obstacle to use this setting.\n",
    "    Decision tree classifer has been used as the predictor and the result is:\n",
    "\n",
    "    Accuracy Score: 0.7891156462585034\n",
    "        \n",
    "For Q3;\n",
    "    According to given information, I used TOTALs of class A and class B with the assumption of they include other column information.\n",
    "    So my predictor is : TOTAL columns of class A and B \n",
    "    The target is : pass/fail condition\n",
    "    I checked distribution of the feature and the target and there is no obstacle to use this setting.\n",
    "    Several different predictors has been tried with cross validation and the GradientBoostingClassifier has been selected.\n",
    "    The results are:\n",
    "    \n",
    "    DecisionTreeClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.8372093  0.86046512 0.94186047]\n",
    "    Mean Accuracy Score - 0.87984496124031\n",
    "    \n",
    "    BaggingClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.84883721 0.87209302 0.94186047]\n",
    "    Mean Accuracy Score - 0.8875968992248061\n",
    "    \n",
    "    RandomForestClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.86046512 0.86046512 0.90697674]\n",
    "    Mean Accuracy Score - 0.8759689922480619\n",
    "    \n",
    "    AdaBoostClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.88372093 0.8372093  0.93023256]\n",
    "    Mean Accuracy Score - 0.883720930232558\n",
    "    \n",
    "    GradientBoostingClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.89534884 0.86046512 0.94186047]\n",
    "    Mean Accuracy Score - 0.8992248062015503\n",
    "\n",
    "For Q4:\n",
    "    According to given information, I used TOTALs of class A, class B and also more recent MT1 score.\n",
    "    So my predictor is : TOTAL columns of class A, B, and MT1 score of class C. \n",
    "    The target is : pass/fail condition\n",
    "    I checked distribution of the feature and the target and there is no obstacle to use this setting.\n",
    "    Several different predictors has been tried with cross validation and the AdaBoostClassifier has been selected.\n",
    "    It is no suprise that our previous accuracy scores in Q3 has improved significantly with new information.\n",
    "    The results are:\n",
    "        \n",
    "    DecisionTreeClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.88372093 0.87209302 0.95348837]\n",
    "    Mean Accuracy Score - 0.9031007751937984\n",
    "    \n",
    "    BaggingClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.91860465 0.86046512 0.93023256]\n",
    "    Mean Accuracy Score - 0.9031007751937984\n",
    "    \n",
    "    RandomForestClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.94186047 0.87209302 0.95348837]\n",
    "    Mean Accuracy Score - 0.9224806201550387\n",
    "    \n",
    "    AdaBoostClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.93023256 0.91860465 0.94186047]\n",
    "    Mean Accuracy Score - 0.9302325581395349\n",
    "    \n",
    "    GradientBoostingClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.93023256 0.88372093 0.95348837]\n",
    "    Mean Accuracy Score - 0.9224806201550387\n",
    "\n",
    "For Q5:\n",
    "    According to given information, I have used all available information.\n",
    "    So my predictor is : columns of class A, B and C. \n",
    "    The target is : GPA Brackets\n",
    "    I checked distribution of the feature and the target and there is no obstacle to use this setting.\n",
    "    Several different predictors has been tried with cross validation and with consideration of \n",
    "        accuracy and MSE, BaggingClassifier has been selected.\n",
    "    It is no suprise that our accuracy score decreased because our classification layers increased.\n",
    "    The results are:\n",
    "        \n",
    "    --------------------Accuracy Scores--------------------------\n",
    "    \n",
    "    DecisionTreeClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.51851852 0.55555556 0.59259259]\n",
    "    Mean Accuracy Score - 0.5555555555555555\n",
    "    BaggingClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.64197531 0.64197531 0.64197531]\n",
    "    Mean Accuracy Score - 0.6419753086419753\n",
    "    RandomForestClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.65432099 0.55555556 0.58024691]\n",
    "    Mean Accuracy Score - 0.5967078189300411\n",
    "    AdaBoostClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.45679012 0.50617284 0.40740741]\n",
    "    Mean Accuracy Score - 0.45679012345679015\n",
    "    GradientBoostingClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [0.62962963 0.58024691 0.59259259]\n",
    "    Mean Accuracy Score - 0.6008230452674898\n",
    "\n",
    "    --------------------MSE Scores--------------------------\n",
    "\n",
    "    DecisionTreeClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [-0.9382716 -0.7037037 -0.7654321]\n",
    "    Mean Accuracy Score - -0.8024691358024691\n",
    "    BaggingClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [-0.54320988 -0.50617284 -0.4691358 ]\n",
    "    Mean Accuracy Score - -0.5061728395061729\n",
    "    RandomForestClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [-0.5308642  -0.61728395 -0.60493827]\n",
    "    Mean Accuracy Score - -0.5843621399176955\n",
    "    AdaBoostClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [-0.72839506 -0.64197531 -0.85185185]\n",
    "    Mean Accuracy Score - -0.7407407407407408\n",
    "    GradientBoostingClassifier\n",
    "    Accuracy Score of each fold\n",
    "    [-0.59259259 -0.67901235 -0.44444444]\n",
    "    Mean Accuracy Score - -0.5720164609053497\n",
    "\n",
    "    However, overfit is a threat which would originated by high number of features and low number of sample size. \n",
    "    I checked overfitting and implemented hyperparameter tuning with randomized search.\n",
    "    the result is;\n",
    "    \n",
    "    Accuracy Score =  0.7551020408163265\n",
    "    \n",
    "    The accuracy increased from 0.60 to 0.76.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs and Manually Implemented Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Class_Grade_Prediction_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. For all the courses data given, use only the data of the respective course and predict\n",
    "the pass/fail condition of the students given that the MT3 score is not available. Please\n",
    "use a 80/20 test train split with a random state parameter equal to 42. Report you\n",
    "accuracy score for each course and provide a detailed explanation of your solution\n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_A_dict is ready\n",
      "class_B_dict is ready\n",
      "class_C_dict is ready\n",
      "aggreated_dict_A is ready\n",
      "categorized_dict_A is ready\n",
      "aggreated_dict_B is ready\n",
      "categorized_dict_B is ready\n",
      "aggreated_dict_C is ready\n",
      "categorized_dict_C is ready\n",
      "q1_df_A is ready\n",
      "q1_df_B is ready\n",
      "q1_df_C is ready\n",
      "final_df_list is ready\n",
      "Class Dispersions\n",
      "Class:A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:C\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#With respect to given information:\n",
    "#Main assumption is; MT3's importance on passing score is not changed over the years for A and B classes.\n",
    "#For class C, it was constant for first 3 years and it just increased %7.5 so it is proper to assume the weight of MT3 constant over the years.\n",
    "\n",
    "\n",
    "#This part creates and aggregates all necessary features and targets. Creates graphs of dispersions.\n",
    "\n",
    "\n",
    "#Re-creating our main dict's to be sure everything is clear and correct\n",
    "class_A_list, class_B_list, class_C_list, class_A_dict, class_B_dict, class_C_dict,GPANew= create_class_dicts()\n",
    "\n",
    "#This part uses former functions that we defined and creates final forms of main dictionaries.\n",
    "for class_letter in ['A', 'B','C']:\n",
    "    class_dict = locals()['class_'+class_letter+'_dict']\n",
    "    #Fiils all MT3 columns with 0, because it is given that we have no clue about this feature.\n",
    "    for dataframes in class_dict.values():\n",
    "        dataframes['MT3'] = 0\n",
    "    #Model decision took place in this section. While doing model; I decided to use only final score as the feature.\n",
    "    #The code which is below calculates final scores without MT3 and transforms Grade column in to binary form.\n",
    "    exec(\"aggreated_dict_\"+class_letter+\" = final_score_calculator(class_dict, class_name = class_letter)\")\n",
    "    exec(\"categorized_dict_\"+class_letter+\" = grade_categorizer(aggreated_dict_\"+class_letter+\")\")\n",
    "    print('aggreated_dict_'+class_letter+' is ready')\n",
    "    #And our output dict is ready to use\n",
    "    print('categorized_dict_'+class_letter+' is ready')\n",
    "    \n",
    "    \n",
    "#Create aggreagated single feature dataframes to create train and test datas.\n",
    "for class_letter in ['A', 'B','C']:\n",
    "    df_list=[]\n",
    "    final_df_list = []\n",
    "    categorized_dict = locals()['categorized_dict_'+class_letter]\n",
    "    #This part concatanates data of each class seperately in to dataframes which are ready to do tran and test split phase.\n",
    "    for value in categorized_dict.values():\n",
    "        df_list.append(value)\n",
    "        locals()['q1_df_'+class_letter] = pd.concat(df_list,keys=list(range(0,len(df_list))))\n",
    "        locals()['q1_df_'+class_letter] = locals()['q1_df_'+class_letter].reset_index().drop(['level_0', 'level_1'],axis = 1)\n",
    "    print('q1_df_'+class_letter+' is ready')\n",
    "\n",
    "#Pack class dataframes in list to iterate easily\n",
    "final_df_list = [q1_df_A, q1_df_B, q1_df_C]\n",
    "print('final_df_list is ready')\n",
    "\n",
    "\n",
    "#Lets view each semesters dispersion with simple scatter plot graphs\n",
    "print('Class Dispersions')\n",
    "for class_df, classy in zip(final_df_list, ['A', 'B', 'C']): \n",
    "    print('Class:' + classy )\n",
    "    scatter_plot_creater(class_df['FINAL_SCORE'],class_df['Grade'], 'Final_Score', 'Grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:A\n",
      "                   \n",
      "Class prediction: \n",
      "                   \n",
      "[[ 7  1]\n",
      " [ 2 42]]\n",
      "                   \n",
      "Accuracy Score: 0.9423076923076923\n",
      "Class:B\n",
      "                   \n",
      "Class prediction: \n",
      "                   \n",
      "[[ 7  3]\n",
      " [ 5 41]]\n",
      "                   \n",
      "Accuracy Score: 0.8571428571428571\n",
      "Class:C\n",
      "                   \n",
      "Class prediction: \n",
      "                   \n",
      "[[ 9  6]\n",
      " [ 1 52]]\n",
      "                   \n",
      "Accuracy Score: 0.8970588235294118\n"
     ]
    }
   ],
   "source": [
    "#This is the decision tree classifier which is our model.\n",
    "for class_df, classy in zip(final_df_list, ['A', 'B', 'C']): \n",
    "    df_feature = class_df['FINAL_SCORE']\n",
    "    target = class_df['Grade']\n",
    "    print('Class:' + classy )\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df_feature, target, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "    my_decision_tree(train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. For Course C, given that 2013, 2014 and 2015 data is fully available and for Spring\n",
    "semester 2018, only MT1 score is available. You are supposed to predict the pass/fail\n",
    "condition of the students in 2018 given the available data. You may use any information\n",
    "regarding Course C (that is 2013, 2014 and 2015 data) as the training data and your\n",
    "test data will be the 2018 student data. Note that the grading scheme and the student\n",
    "body has changed over the years. Once again report your accuracy score and provide\n",
    "a detailed explanation of your solution method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_A_dict is ready\n",
      "class_B_dict is ready\n",
      "class_C_dict is ready\n",
      "First 3 semesters (train data)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFdCAYAAADWns55AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHpNJREFUeJzt3XuYZHV95/H3Z4ZBR0QQGbMyMzDEIAY1XGwFYh7XKAngGiDGC0Q3bmIg7up6DVndGNcYE2PIEpMNJsFo3BgD0URx1qDoekmMq8AgyjWzjqjMAIZBQI2iDsM3f9QZLJrq6erpPtO/mn6/nqef7vOr3znn+6tTpz99Ll2VqkKSJLVh2WIXIEmSfsBgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS7tJktcn+avFrmNYkg8lecFi17FDkj9N8huLXYe0mPZa7AKkPUmSnwdeCTwa+BbweeC3q+qfFqGWAr4DFPC9rpbzq+pvdvSpqpN3d107U1UvWuwapMXmEbO0QJK8EngL8DvADwEHA28FTl3Eso6sqgcDhwPvBP44yf9YrGKSeDAgzcJglhZAkv2ANwAvrqr3VdW3q2pbVf2fqjp7hnnem+RrSb6R5B+TPGbosacnuS7Jt5LclORXu/YDk3wwyZ1Jbk/yqSSz7sdVdVtVvQv4z8BrkjysW94nk/xy9/OPJPmHrp7bktx7ZJ2kkrw0yQ3dY+cMrzfJLyW5PskdSS5Jcsi0eV+c5IvAFzPwB0lu7dZ1VZLHdn3fmeSNQ/OemWRTN9b1SQ6attwXJflit97zkmTWjSU1zmCWFsbxwAOB989hng8BhwEPBz4HvHvosbcDv1JV+wKPBT7etb8K2AKsYnBU/t8ZnKoe1wcYXMJ64ojHfgv4CPBQYA3wv6Y9/rPAFHAMg7MAvwSQ5LSujmd2dX0KuGDavKcBxwJHAD8NPBl4FLA/8Fzg69OLSfJU4E3Ac4BHAF8FLpzW7RnAE4Aju34nzjx0aTIYzNLCeBhwW1XdPe4MVfWOqvpWVX0PeD1wZHfkDbANOCLJQ6rqjqr63FD7I4BDuiPyT9Uc3vC+qrYBtwEHjHh4G3AIcFBVfXfEdfE3V9XtVXUjg1P2Z3TtvwK8qaqu78b/O8BRw0fN3eO3V9Vd3Xr2ZXAdPt18t4yo53nAO6rqc91z9Brg+CTrhvr8blXd2dX0CeCocZ8LqVUGs7Qwvg4cOO411CTLk/xuki8l+Sbwle6hA7vvPwc8Hfhqd3r5+K79HGAT8JHutPKr51JkkhUMjmpvH/HwrwEBLktybZJfmvb45qGfvwrsOK18CPCH3en1O7tlB1g9at6q+jjwx8B5wL8kOT/JQ0bUc1C3nh3z/SuD53l4uV8b+vk7wINHLEeaKAaztDA+A3yXwSnbcfw8g9PBJwD7Aeu69gBU1eVVdSqD09wXAe/p2r9VVa+qqh8GfgZ4ZZKnzaHOU4G7gcumP1BVX6uqM6vqIAZHwW9N8iNDXdYO/XwwcHP382YGp933H/paWVX/b3jx09b1R1X1eOAxDE5pj7oOfzOD0AcgyT4MzkzcNOZYpYlkMEsLoKq+AbwOOC/JaUkelGRFkpOT/N6IWfZl8C9MXwcexOD0LwBJ9k7yvCT7daeevwls7x57RneTVobat89WX5IDkjyPwVHqm6tq1DXdZydZ003ewSBMh5d9dpKHJlkLvAzYcXPYnzK4oewx3XL2S/LsndTyhCTHdkfv32bwB82oMfw18ItJjkryAAbP0aVV9ZXZxitNMoNZWiBVdS6D/2F+LbCVwZHkSxgc8U73lwxO094EXAd8dtrj/xH4Snea+0XA87v2w4D/C/wrg6P0t1bVJ3dS1heS/CuD09+/DLyiql43Q98nAJd2/dcDL6uqLw89/gHgCgb/D/33DG5Qo6reD7wZuLCr9xpgZ/8f/RDgbQzC/6sM/jj5/emdqupjwG8AfwfcAjwSOH0ny5X2CJnDfSOSlqjuzUoOq6pNi12LtKfziFmSpIYYzJIkNcRT2ZIkNcQjZkmSGmIwS5LUkIn7pJcDDzyw1q1bt9hlSJI0J1dcccVtVbVqtn4TF8zr1q1jw4YNi12GJElzkuSrs/fyVLYkSU0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWpIb8Gc5B1Jbk1yzQyPJ8kfJdmU5Kokx/RViyRJk6LP98p+J/DHwF/O8PjJwGHd17HAn3Tfl5yLrryJcy7ZyM133sVB+6/k7BMP57SjVzezjlHzAmO1bfjq7Vxw6Wa2V7E84Yxj1/LG0x7Xe81zmf+1F119vxqB+7VNHXLA/Zb33g038ukv3X7vsp70yAN495nHL+hzOGodz546eJef/1Fjm894D1314LG28bjPwahttND7yEzL2x017q6xjNNv3P1zPs/LQo9j1P467u+UcT3vbZ8Za7/uS6qqv4Un64APVtVjRzz2Z8Anq+qCbnoj8JSqumVny5yamqo96UMsLrryJl7zvqu5a9v2e9tWrljOm575uAUL5/msY9S8K5YFAtu2/+C1s2J5oGDbPT9oWwbcM2KZzz/u4Fl3pPk+L+PO/9qLruavPnvjrMsDWL4sbL9n9v1l+k489nM4om1ZYNQqp7fPZd5xzbT9xjF9G4/7HIzaRgu9j8y0vJ97/Gr+7oqbeq1xd41lnPWOu3/OZ9st9Dhm2l/H+Z0yrumhvMNChHOSK6pqarZ+i3mNeTWweWh6S9e2pJxzycb7vBgB7tq2nXMu2djEOkbNu+2eus8OCYMddNu0FJjpl/oFl26e4ZGFqXku849Tyw7jhDJwv5167OdwRNtMq5zePpd5x7WroQz3f17HfQ5GbaOF3kdmWt4Fl27uvcbdNZZx1jvu/jmfbTeu+e6vc9mPZzMqlHfW3ofFDOaMaBv5qyTJWUk2JNmwdevWnsvavW6+8645te/udSxkHTtsH+MszXyfl3HnH6eW+erjOWzd9Od1Ls/B9L4LvY/MNN9cXgu7WuPuGsu46x1lIbfdfOcbd3/dHfvx7rSYwbwFWDs0vQa4eVTHqjq/qqaqamrVqlk/Y3qiHLT/yjm17+51LGQdOyzPqL/JxlvvuPWMO/84tcxXH89h66Y/r3N5Dqb3Xeh9ZKb55vJa2NUad9dYxl3vKAu57eY737j76+7Yj3enxQzm9cAvdHdnHwd8Y7bry3uis088nJUrlt+nbeWK5ffeXLHY6xg174plGVxTHm5bnsF1pyEzvbh23GzUV81zmX+cWnZYvmy8nf9Jjzxg1lpGPocj2mZa5fT2ucw7rvn8cpj+vI77HIzaRgu9j8y0vDOOXdt7jbtrLOOsd9z9cz7bblzz3V/nsh/PZvr+O1t7H/r8d6kLgM8AhyfZkuSFSV6U5EVdl4uBG4BNwNuA/9JXLS077ejVvOmZj2P1/isJsHr/lQt649d81zFq3nOefSTnPOvI+7Y960jOefZ928597lE8/7iD7/1rdnky9k0a831exp3/jac9bmSNo9r+57TxveW5R91vZx11g8jYz+GItnOfM3od5z7nqLHmHXdso9rOfe5RY413nG087nMwahst9D4y0/LeeNrjeq9xd41lnPWOu3/OZ9st9Dhm2l8X8q7sd595/Fj7dZ96vSu7D3vaXdmSpKVhEu7KliRJ0xjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDWk12BOclKSjUk2JXn1iMcPTvKJJFcmuSrJ0/usR5Kk1vUWzEmWA+cBJwNHAGckOWJat9cC76mqo4HTgbf2VY8kSZOgzyPmJwKbquqGqvo+cCFw6rQ+BTyk+3k/4OYe65EkqXl79bjs1cDmoektwLHT+rwe+EiS/wrsA5zQYz2SJDWvzyPmjGiradNnAO+sqjXA04F3JblfTUnOSrIhyYatW7f2UKokSW3oM5i3AGuHptdw/1PVLwTeA1BVnwEeCBw4fUFVdX5VTVXV1KpVq3oqV5KkxddnMF8OHJbk0CR7M7i5a/20PjcCTwNI8qMMgtlDYknSktVbMFfV3cBLgEuA6xncfX1tkjckOaXr9irgzCRfAC4A/lNVTT/dLUnSktHnzV9U1cXAxdPaXjf083XAk/qsQZKkSeI7f0mS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDWk12BOclKSjUk2JXn1DH2ek+S6JNcm+es+65EkqXV79bXgJMuB84CfArYAlydZX1XXDfU5DHgN8KSquiPJw/uqR5KkSdDnEfMTgU1VdUNVfR+4EDh1Wp8zgfOq6g6Aqrq1x3okSWpen8G8Gtg8NL2laxv2KOBRST6d5LNJThq1oCRnJdmQZMPWrVt7KleSpMXXZzBnRFtNm94LOAx4CnAG8OdJ9r/fTFXnV9VUVU2tWrVqwQuVJKkVfQbzFmDt0PQa4OYRfT5QVduq6svARgZBLUnSktRnMF8OHJbk0CR7A6cD66f1uQj4SYAkBzI4tX1DjzVJktS03oK5qu4GXgJcAlwPvKeqrk3yhiSndN0uAb6e5DrgE8DZVfX1vmqSJKl1qZp+2bdtU1NTtWHDhsUuQ5KkOUlyRVVNzdbPd/6SJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIaMFcxJHpXkY0mu6aZ/LMlr+y1NkqSlZ9wj5rcx+NzkbQBVdRWDt9iUJEkLaNxgflBVXTat7e6FLkaSpKVu3GC+Lckj6T62McmzgFt6q0qSpCVqrzH7vRg4H3h0kpuALwPP760qSZKWqLGCuapuAE5Isg+wrKq+1W9ZkiQtTTsN5iSvnKEdgKo6t4eaJElasmY7Yt63+3448ARgfTf9M8A/9lWUJElL1U6Duap+EyDJR4BjdpzCTvJ64L29VydJ0hIz7l3ZBwPfH5r+PrBuwauRJGmJG/eu7HcBlyV5P4N/mfpZ4C97q0qSpCVq3LuyfzvJh4Gf6Jp+saqu7K8sSZKWpnGPmKmqK5JsBh4IkOTgqrqxt8okSVqCxv0Qi1OSfJHBG4v8Q/f9Q30WJknSUjTuzV+/BRwH/P+qOhQ4Afh0b1VJkrREjRvM26rq68CyJMuq6hPAUT3WJUnSkjTuNeY7kzyYwZuKvDvJrfjpUpIkLbhxj5hPBb4DvAL4MPAlBu/+JUmSFtCsR8xJlgMfqKoTgHuA/917VZIkLVGzHjFX1XbgO0n22w31SJK0pI17jfm7wNVJPgp8e0djVb20l6okSVqixg3mv+++YPCWnABZ+HIkSVraZvs85lOBNVV1Xjd9GbCKQTj/t/7LkyRpaZntGvOv8YPPYAbYG3g88BTgRT3VJEnSkjXbqey9q2rz0PQ/VdXtwO1J9umxLkmSlqTZjpgfOjxRVS8Zmly18OVIkrS0zRbMlyY5c3pjkl8BLuunJEmSlq7ZTmW/Argoyc8Dn+vaHg88ADitz8IkSVqKdhrMVXUr8ONJngo8pmv++6r6eO+VSZK0BI31f8xdEBvGkiT1bNwPsZAkSbuBwSxJUkMMZkmSGmIwS5LUEINZkqSG9BrMSU5KsjHJpiSv3km/ZyWpJFN91iNJUut6C+Yky4HzgJOBI4Azkhwxot++wEuBS/uqRZKkSdHnEfMTgU1VdUNVfR+4EDh1RL/fAn4P+G6PtUiSNBH6DObVwPAnU23p2u6V5GhgbVV9cGcLSnJWkg1JNmzdunXhK5UkqRF9BnNGtNW9DybLgD8AXjXbgqrq/KqaqqqpVav8UCtJ0p6rz2DeAqwdml4D3Dw0vS/wWOCTSb4CHAes9wYwSdJS1mcwXw4cluTQJHsDpwPrdzxYVd+oqgOral1VrQM+C5xSVRt6rEmSpKb1FsxVdTfwEuAS4HrgPVV1bZI3JDmlr/VKkjTJxvp0qV1VVRcDF09re90MfZ/SZy2SJE0C3/lLkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNaTXYE5yUpKNSTYlefWIx1+Z5LokVyX5WJJD+qxHkqTW9RbMSZYD5wEnA0cAZyQ5Ylq3K4Gpqvox4G+B3+urHkmSJkGfR8xPBDZV1Q1V9X3gQuDU4Q5V9Ymq+k43+VlgTY/1SJLUvD6DeTWweWh6S9c2kxcCH+qxHkmSmrdXj8vOiLYa2TF5PjAF/PsZHj8LOAvg4IMPXqj6JElqTp9HzFuAtUPTa4Cbp3dKcgLw68ApVfW9UQuqqvOraqqqplatWtVLsZIktaDPYL4cOCzJoUn2Bk4H1g93SHI08GcMQvnWHmuRJGki9BbMVXU38BLgEuB64D1VdW2SNyQ5pet2DvBg4L1JPp9k/QyLkyRpSejzGjNVdTFw8bS21w39fEKf65ckadL4zl+SJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIb0Gc5KTkmxMsinJq0c8/oAkf9M9fmmSdX3WI0lS6/bqa8FJlgPnAT8FbAEuT7K+qq4b6vZC4I6q+pEkpwNvBp7bV03DLrryJs65ZCM333kXB+2/krNPPJzTjl491ryvvehqLrh0M9urWJ5wxrFreeNpj9vldYxa3tQhByxoffNZ3iijxgYs6DrGXe9M65jPNpakxZKq6mfByfHA66vqxG76NQBV9aahPpd0fT6TZC/ga8Cq2klRU1NTtWHDhnnVdtGVN/Ga913NXdu239u2csVy3vTMx836i/u1F13NX332xvu1P/+4g+8TzuOuY6blLV8Wtt9TO513LvXt6vJGGTW2FcsCgW3bF2Yd4653pnXMZxtLUh+SXFFVU7P16/NU9mpg89D0lq5tZJ+quhv4BvCwHmsCBkd1w7+wAe7atp1zLtk467wXXLp5rPZx1zHT8oZDdCHq29XljTJqbNvuqfuE8nzXMe56Z1rHfLaxJC2mPoM5I9qmHwmP04ckZyXZkGTD1q1b513YzXfeNaf2YdtnOJif3j7uOmZa3jjzjlPHfJc33/l2dR1zWdao9vlsY0laTH0G8xZg7dD0GuDmmfp0p7L3A26fvqCqOr+qpqpqatWqVfMu7KD9V86pfdjyjPpb4v7t465jpuWNM+84dcx3efOdb1fXMZdljWqfzzaWpMXUZzBfDhyW5NAkewOnA+un9VkPvKD7+VnAx3d2fXmhnH3i4axcsfw+bStXLL/3BqadOePYtWO1j7uOmZa3fNl9A3a+9e3q8kYZNbYVy8KK5Qu3jnHXO9M65rONJWkx9XZXdlXdneQlwCXAcuAdVXVtkjcAG6pqPfB24F1JNjE4Uj69r3qG7bj5Z1fu2N1xg9dsd2WPu46Zlrerd1Ev9PJGmWls44x3Puay3eazjSVpMfV2V3ZfFuKubEmSdrcW7sqWJElzZDBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGTNx7ZSfZCnx1jK4HArf1XM7u4Djas6eMxXG0Z08Zi+MY7ZCqmvWziycumMeVZMM4bxbeOsfRnj1lLI6jPXvKWBzH/HgqW5KkhhjMkiQ1ZE8O5vMXu4AF4jjas6eMxXG0Z08Zi+OYhz32GrMkSZNoTz5iliRp4kx8MCdZm+QTSa5Pcm2Sl3XtByT5aJIvdt8futi1zibJA5NcluQL3Vh+s2s/NMml3Vj+Jsnei13rOJIsT3Jlkg920xM3jiRfSXJ1ks8n2dC1TeJra/8kf5vkn7t95fgJHcfh3bbY8fXNJC+f0LG8otvPr0lyQbf/T+I+8rJuDNcmeXnXNhHbI8k7ktya5JqhtpG1Z+CPkmxKclWSY/qqa+KDGbgbeFVV/ShwHPDiJEcArwY+VlWHAR/rplv3PeCpVXUkcBRwUpLjgDcDf9CN5Q7ghYtY41y8DLh+aHpSx/GTVXXU0L9NTOJr6w+BD1fVo4EjGWyXiRtHVW3stsVRwOOB7wDvZ8LGkmQ18FJgqqoeCywHTmfC9pEkjwXOBJ7I4HX1jCSHMTnb453ASdPaZqr9ZOCw7uss4E96q6qq9qgv4APATwEbgUd0bY8ANi52bXMcx4OAzwHHMvgH97269uOBSxa7vjHqX9O9qJ8KfBDIhI7jK8CB09om6rUFPAT4Mt09JZM6jhHj+mng05M4FmA1sBk4ANir20dOnLR9BHg28OdD078B/NokbQ9gHXDN0PTI2oE/A84Y1W+hv/aEI+Z7JVkHHA1cCvxQVd0C0H1/+OJVNr7u9O/ngVuBjwJfAu6sqru7LlsY7NStewuDHfSebvphTOY4CvhIkiuSnNW1Tdpr64eBrcBfdJcW/jzJPkzeOKY7Hbig+3mixlJVNwG/D9wI3AJ8A7iCydtHrgGenORhSR4EPB1Yy4Rtj2lmqn3HH1M79LZ99phgTvJg4O+Al1fVNxe7nl1VVdtrcJpuDYPTQz86qtvurWpukjwDuLWqrhhuHtG16XF0nlRVxzA4jfXiJE9e7IJ2wV7AMcCfVNXRwLdp99TiWLprr6cA713sWnZFd93yVOBQ4CBgHwavsema3keq6noGp98/CnwY+AKDy4t7ot32O2yPCOYkKxiE8rur6n1d878keUT3+CMYHIFOjKq6E/gkg+vm+yfZq3toDXDzYtU1picBpyT5CnAhg9PZb2HyxkFV3dx9v5XBtcwnMnmvrS3Alqq6tJv+WwZBPWnjGHYy8Lmq+pduetLGcgLw5araWlXbgPcBP85k7iNvr6pjqurJwO3AF5m87TFsptq3MDgbsENv22figzlJgLcD11fVuUMPrQde0P38AgbXnpuWZFWS/bufVzLYea8HPgE8q+vW/Fiq6jVVtaaq1jE43fjxqnoeEzaOJPsk2XfHzwyuaV7DhL22quprwOYkh3dNTwOuY8LGMc0Z/OA0NkzeWG4EjkvyoO532I5tMlH7CECSh3ffDwaeyWC7TNr2GDZT7euBX+juzj4O+MaOU94LbrEvvC/AhfufYHA64Srg893X0xlc0/wYg7/ePgYcsNi1jjGWHwOu7MZyDfC6rv2HgcuATQxO3T1gsWudw5ieAnxwEsfR1fuF7uta4Ne79kl8bR0FbOheWxcBD53EcXRjeRDwdWC/obaJGwvwm8A/d/v6u4AHTNo+0o3jUwz+qPgC8LRJ2h4M/oi4BdjG4Ij4hTPVzuBU9nkM7vu5msEd9b3U5Tt/SZLUkIk/lS1J0p7EYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZpiUhSSd41NL1Xkq1JPpjkF4c+sen7+cEnav1ukkcn+UyS7yX51cUcg7QU7DV7F0l7iG8Dj02ysqruYvBhLzcBVNVfAH8Bg4+6ZPCJWrd10w9n8ElIpy1G0dJS4xGztLR8CPgP3c/T3z1rpKq6taouZ/AmDJJ6ZjBLS8uFwOlJHsjgneYunaW/pN3MYJaWkKq6isHnz54BXLy41UgaxWvM0tKznsFnAT+FwfsCS2qIwSwtPe9g8Mk4Vyd5ymIXI+m+DGZpiamqLcAfjts/yb9j8MlUDwHuSfJy4Iiq+mZPJUpLmp8uJUlSQ7z5S5KkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktSQfwP9Psh2wyb7GAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last semester (test data)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Re-creating our main dict's to be sure everything is clear and correct\n",
    "class_A_list, class_B_list, class_C_list, class_A_dict, class_B_dict, class_C_dict,GPANew = create_class_dicts()\n",
    "\n",
    "#Create a copy of our main dictionary. Just a reflex to protection.\n",
    "class_C_dict2 = class_C_dict.copy()\n",
    "\n",
    "#Exctract necessary parts of our raw data and pick MT1 and Grade columns\n",
    "for key, value in class_C_dict2.items():\n",
    "    class_C_dict2[key] = value[['MT1', 'Grade']]   \n",
    "\n",
    "#Transform Grade column to a categoric one.\n",
    "class_C_dict2 = grade_categorizer(class_C_dict2)\n",
    "\n",
    "#Here is our target semester\n",
    "df_C2018New = class_C_dict2['C2018New']\n",
    "\n",
    "#Unpacking necessary semesters from our main dict and appending them in to a list (list of semester dfs)\n",
    "train_semester_list = ['C2013New', 'C2014New','C2015New']\n",
    "first_3_semesters_list = [value for (key,value) in class_C_dict2.items() if key in train_semester_list] \n",
    "\n",
    "\n",
    "#Scatter plots of each class in terms of final scores without MT3 and binary form of grades\n",
    "import matplotlib.pyplot as plt\n",
    "print('First 3 semesters (train data)')\n",
    "for i in list(range(0,3)):\n",
    "    scatter_plot_creater(first_3_semesters_list[i]['MT1'],first_3_semesters_list[i]['Grade'], 'MT1', 'Grade')\n",
    "print('Last semester (test data)')\n",
    " \n",
    "scatter_plot_creater(df_C2018New['MT1'],df_C2018New['Grade'], 'MT1', 'Grade')\n",
    "    \n",
    "#According to below graphs of prior semesters, it is possible to see that there is almost exact relationship between MT1 Grade and the passing condition\n",
    "#However what we know is, weight of MT1 changed last semester and information is limited with MT1.\n",
    "#So it would be a good idea to apply weights of each semester and run a model afterwards. \n",
    "#However, I tried and it was -obviously- not a good idea.\n",
    "#So I decided to go simple and trained as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   \n",
      "Class prediction: \n",
      "                   \n",
      "[[41 10]\n",
      " [21 75]]\n",
      "                   \n",
      "Accuracy Score: 0.7891156462585034\n"
     ]
    }
   ],
   "source": [
    "#training dataframe\n",
    "semester_df = pd.concat(first_3_semesters_list,keys=list(range(0,len(df_list))))\n",
    "semester_df.reset_index().drop(['level_0', 'level_1'],axis = 1)\n",
    "\n",
    "#test dataframe\n",
    "df_C2018New\n",
    "\n",
    "train_x = semester_df['MT1']\n",
    "train_y = semester_df['Grade']\n",
    "test_x = df_C2018New['MT1']\n",
    "test_y = df_C2018New['Grade']\n",
    "\n",
    "my_decision_tree(train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.Assume that you have the full data available for Course A and B for years 2013, 2014\n",
    "and 2015. You are supposed to predict the pass/fail condition of the Course C students\n",
    "for years 2013, 2014 and 2015 with no information regarding Course C. Note that the\n",
    "students are mostly the same students in these courses although there might a semester\n",
    "shift (so one particular student taking Course A in 2013 but Course C in 2015). You\n",
    "prediction will be based solely on the information of the student in previous courses.\n",
    "Once again report your accuracy score and provide a detailed explanation of your\n",
    "solution method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_A_dict is ready\n",
      "class_B_dict is ready\n",
      "class_C_dict is ready\n"
     ]
    }
   ],
   "source": [
    "#Re-creating our main dict's to be sure everything is clear and correct\n",
    "class_A_list, class_B_list, class_C_list, class_A_dict, class_B_dict, class_C_dict,GPANew = create_class_dicts()\n",
    "\n",
    "#Create a copy of our main dictionary. Just a reflex to protection.\n",
    "class_A_dict2 = class_A_dict.copy()\n",
    "class_B_dict2 = class_B_dict.copy()\n",
    "class_C_dict2 = class_C_dict.copy()\n",
    "\n",
    "#Exctract necessary parts of our raw data and pick MT1 and Grade columns\n",
    "class_list = [class_A_dict2,class_B_dict2,class_C_dict2]\n",
    "for class_dict in class_list:\n",
    "    for key, value in class_dict.items():\n",
    "        class_dict[key] = value[['StudentID', 'TOTAL', 'Grade']] \n",
    "    class_dict = grade_categorizer(class_dict)\n",
    "    \n",
    "#converting target data: class A in to a non-duplicate, categorized and fitered dataframe form\n",
    "target_semestername_list = ['C2013New', 'C2014New','C2015New']\n",
    "target_semesters_list = [value for (key,value) in class_C_dict2.items() if key in target_semestername_list] \n",
    "#Target dataframe\n",
    "c_semester_df = pd.concat(target_semesters_list,join = 'outer', keys = 'StudentID')\n",
    "c_semester_df = c_semester_df.reset_index().drop(['level_0', 'level_1','TOTAL'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns={\"Grade\": \"Grade_C\"})\n",
    "\n",
    "\n",
    "#converting train data:class A in to a non-duplicate, categorized and fitered dataframe form \n",
    "train_semestername_list_A = ['A2013New', 'A2014New','A2015New']\n",
    "train_semesters_list_A = [value for (key,value) in class_A_dict2.items() if key in train_semestername_list_A] \n",
    "a_semester_df = pd.concat(train_semesters_list_A,join = 'outer', keys = 'StudentID')\n",
    "a_semester_df = a_semester_df.reset_index().drop(['level_0', 'level_1'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns={\"TOTAL\": \"TOTAL_A\", \"Grade\": \"Grade_A\"})\n",
    "\n",
    "#converting train data:class B in to a non-duplicate, categorized and fitered dataframe form \n",
    "train_semestername_list_B = ['B2013New', 'B2014New','B2015New']\n",
    "train_semesters_list_B = [value for (key,value) in class_B_dict2.items() if key in train_semestername_list_B] \n",
    "b_semester_df = pd.concat(train_semesters_list_B,join = 'outer', keys = 'StudentID')\n",
    "b_semester_df = b_semester_df.reset_index().drop(['level_0', 'level_1'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns={\"TOTAL\": \"TOTAL_B\", \"Grade\": \"Grade_B\"})\n",
    "\n",
    "#Merge our features data class A, B and target class A dataframes in to one on StudentID key\n",
    "#Filling NaN values with 1 is not a knowledge decision, I tried several possibilities, like 0, 999. Best solution is reached by 1\n",
    "full_data_df = pd.merge(a_semester_df, pd.merge(c_semester_df, b_semester_df,how= 'outer', on = 'StudentID' ),how= 'outer', on = 'StudentID' ).fillna(1)\n",
    "\n",
    "#This step is unnecessary in case of usage of cross validation function, however it was necessary while I was doing my trials on different models.\n",
    "df_feature = full_data_df[['TOTAL_A','Grade_A','TOTAL_B', 'Grade_B']]\n",
    "target = full_data_df['Grade_C']\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_feature, target, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "#my_decision_tree(train_x,train_y,test_x,test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDecisionTreeClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.8372093  0.84883721 0.86046512]\n",
      "Mean Accuracy Score - \u001b[4m0.8488372093023256\u001b[0m\n",
      "\u001b[1mBaggingClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.84883721 0.87209302 0.94186047]\n",
      "Mean Accuracy Score - \u001b[4m0.8875968992248061\u001b[0m\n",
      "\u001b[1mRandomForestClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.86046512 0.87209302 0.90697674]\n",
      "Mean Accuracy Score - \u001b[4m0.87984496124031\u001b[0m\n",
      "\u001b[1mAdaBoostClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.88372093 0.8372093  0.93023256]\n",
      "Mean Accuracy Score - \u001b[4m0.883720930232558\u001b[0m\n",
      "\u001b[1mGradientBoostingClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.89534884 0.86046512 0.94186047]\n",
      "Mean Accuracy Score - \u001b[4m0.8992248062015503\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#We are trying new classifiers in question 3 as a result of multiple inputs.\n",
    "#Q1 and Q2 have had single dimension features.So It was unnecessary to implement multiple classifiers.\n",
    "#define desired predictors\n",
    "clf = DecisionTreeClassifier()\n",
    "bgc = BaggingClassifier(base_estimator=clf, n_estimators=10, random_state=42)\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "abc = AdaBoostClassifier(n_estimators=10, random_state=42)\n",
    "sgb = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "#predictors list\n",
    "classifier_list = [clf,bgc,rfc,abc,sgb]\n",
    "\n",
    "#Calculate mean cv scores and view accuracies for each fold\n",
    "classifier_name = []\n",
    "cv_score_list = []\n",
    "mean_cvs = []\n",
    "for i in classifier_list:\n",
    "    print('\\033[1m'+str(i)[0:str(i).find('(')]+'\\033[0m')\n",
    "    classifier_name.append(str(i)[0:str(i).find('(')])\n",
    "    cv_scores, mean_cv = lets_cross_validate(i, df_feature, target, cv = KFold(3, shuffle = True, random_state = 42), scoring = 'accuracy')\n",
    "    cv_score_list.append(cv_scores)\n",
    "    mean_cvs.append(mean_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "So we choose GradientBoostingClassifier as a result of its success in accuracy score.\n",
    "\n",
    "GradientBoostingClassifier\n",
    "Accuracy Score of each fold\n",
    "\n",
    "[0.89534884 0.86046512 0.94186047]\n",
    "\n",
    "Mean Accuracy Score - 0.8992248062015503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Similar to the previous question, but this time MT1 score is available for all the re-\n",
    "spective semester for Course C. Therefore, your predictions will not be solely based\n",
    "on student previous performance but this partially this course's data as well. Once\n",
    "again report your accuracy score and provide a detailed explanation of your solution\n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_A_dict is ready\n",
      "class_B_dict is ready\n",
      "class_C_dict is ready\n"
     ]
    }
   ],
   "source": [
    "#Re-creating our main dict's to be sure everything is clear and correct\n",
    "class_A_list, class_B_list, class_C_list, class_A_dict, class_B_dict, class_C_dict,GPANew= create_class_dicts()\n",
    "\n",
    "#Create a copy of our main dictionary. Just a reflex to protection.\n",
    "class_A_dict2 = class_A_dict.copy()\n",
    "class_B_dict2 = class_B_dict.copy()\n",
    "class_C_dict2 = class_C_dict.copy()\n",
    "\n",
    "#Exctract necessary parts of our raw data and pick MT1 and Grade columns\n",
    "class_list = [class_A_dict2,class_B_dict2,class_C_dict2]\n",
    "for class_dict in class_list:\n",
    "    for key, value in class_dict.items():\n",
    "        class_dict[key] = value[['StudentID','MT1', 'TOTAL', 'Grade']] \n",
    "    class_dict = grade_categorizer(class_dict)\n",
    "    \n",
    "#converting target data: class A in to a non-duplicate, categorized and fitered dataframe form\n",
    "target_semestername_list = ['C2013New', 'C2014New','C2015New']\n",
    "target_semesters_list = [value for (key,value) in class_C_dict2.items() if key in target_semestername_list] \n",
    "#Target dataframe\n",
    "c_semester_df = pd.concat(target_semesters_list,join = 'outer', keys = 'StudentID')\n",
    "c_semester_df = c_semester_df.reset_index().drop(['level_0', 'level_1','TOTAL'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns={\"Grade\": \"Grade_C\"})\n",
    "\n",
    "\n",
    "#converting train data:class A in to a non-duplicate, categorized and fitered dataframe form \n",
    "train_semestername_list_A = ['A2013New', 'A2014New','A2015New']\n",
    "train_semesters_list_A = [value for (key,value) in class_A_dict2.items() if key in train_semestername_list_A] \n",
    "a_semester_df = pd.concat(train_semesters_list_A,join = 'outer', keys = 'StudentID')\n",
    "a_semester_df = a_semester_df.reset_index().drop(['level_0', 'level_1','MT1'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns={\"TOTAL\": \"TOTAL_A\", \"Grade\": \"Grade_A\"})\n",
    "\n",
    "#converting train data:class B in to a non-duplicate, categorized and fitered dataframe form \n",
    "train_semestername_list_B = ['B2013New', 'B2014New','B2015New']\n",
    "train_semesters_list_B = [value for (key,value) in class_B_dict2.items() if key in train_semestername_list_B] \n",
    "b_semester_df = pd.concat(train_semesters_list_B,join = 'outer', keys = 'StudentID')\n",
    "b_semester_df = b_semester_df.reset_index().drop(['level_0', 'level_1','MT1'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns={\"TOTAL\": \"TOTAL_B\", \"Grade\": \"Grade_B\"})\n",
    "\n",
    "#Merge our features data class A, B and target class A dataframes in to one on StudentID key\n",
    "#Filling NaN values with 1 is not a knowledge decision, I tried several possibilities, like 0, 999. Best solution is reached by 1\n",
    "full_data_df = pd.merge(a_semester_df, pd.merge(c_semester_df, b_semester_df,how= 'outer', on = 'StudentID' ),how= 'outer', on = 'StudentID' ).fillna(1)\n",
    "\n",
    "#This step is unnecessary in case of usage of cross validation function, however it was necessary while I was doing my trials on different models.\n",
    "df_feature = full_data_df[['TOTAL_A','Grade_A','TOTAL_B', 'Grade_B','MT1']]\n",
    "target = full_data_df['Grade_C']\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_feature, target, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "#my_decision_tree(train_x,train_y,test_x,test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDecisionTreeClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.90697674 0.88372093 0.93023256]\n",
      "Mean Accuracy Score - \u001b[4m0.9069767441860465\u001b[0m\n",
      "\u001b[1mBaggingClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.91860465 0.86046512 0.93023256]\n",
      "Mean Accuracy Score - \u001b[4m0.9031007751937984\u001b[0m\n",
      "\u001b[1mRandomForestClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.94186047 0.87209302 0.95348837]\n",
      "Mean Accuracy Score - \u001b[4m0.9224806201550387\u001b[0m\n",
      "\u001b[1mAdaBoostClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.93023256 0.91860465 0.94186047]\n",
      "Mean Accuracy Score - \u001b[4m0.9302325581395349\u001b[0m\n",
      "\u001b[1mGradientBoostingClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.93023256 0.88372093 0.95348837]\n",
      "Mean Accuracy Score - \u001b[4m0.9224806201550387\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#We are trying new classifiers in question 3 as a result of multiple inputs.\n",
    "#Q1 and Q2 have had single dimension features.So It was unnecessary to implement multiple classifiers.\n",
    "#define desired predictors\n",
    "clf = DecisionTreeClassifier()\n",
    "bgc = BaggingClassifier(base_estimator=clf, n_estimators=10, random_state=42)\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "abc = AdaBoostClassifier(n_estimators=10, random_state=42)\n",
    "sgb = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "#predictors list\n",
    "classifier_list = [clf,bgc,rfc,abc,sgb]\n",
    "\n",
    "#Calculate mean cv scores and view accuracies for each fold\n",
    "classifier_name = []\n",
    "cv_score_list = []\n",
    "mean_cvs = []\n",
    "for i in classifier_list:\n",
    "    print('\\033[1m'+str(i)[0:str(i).find('(')]+'\\033[0m')\n",
    "    classifier_name.append(str(i)[0:str(i).find('(')])\n",
    "    cv_scores, mean_cv = lets_cross_validate(i, df_feature, target, cv = KFold(3, shuffle = True, random_state = 42), scoring = 'accuracy')\n",
    "    cv_score_list.append(cv_scores)\n",
    "    mean_cvs.append(mean_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "We did almost the same thing in Q3 - only with MT1 score of class C- and tables have turned. \n",
    "So there is no harm to give a look to roc_auc score in decision process.\n",
    "AdaBoostClassifier: 0.869\n",
    "GradientBoostingClassifier: 0.899\n",
    "\n",
    "MT1's marginal effect is really high and significant in both accuracy and roc_auc\n",
    "\n",
    "However, we choose AdaBoostClassifier with a higher accuracy and inner peace, thanks to MT1 scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finally, given the grade performance of the student in all these courses, you are sup-\n",
    "posed to predict the GPA bracket of the students (only the students taking at least one\n",
    "course out of A,B and C in years 2013, 2014 and 2015). The brackets are de\f",
    "ned as\n",
    "2.00-2.50, 2.50-3.00, 3.00-3.50 and \f",
    "nally 3.50-4.00. Besides the accuracy score, please\n",
    "consider Mean Square Error as another criterion while brackets are ordered as 1, 2,\n",
    "3, and 4 respectively and predicting a close bracket is preferable to otherwise. Once\n",
    "again report your accuracy score, MSE score and provide a detailed explanation of\n",
    "your solution method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_A_dict is ready\n",
      "class_B_dict is ready\n",
      "class_C_dict is ready\n"
     ]
    }
   ],
   "source": [
    "#Re-creating our main dict's to be sure everything is clear and correct\n",
    "class_A_list, class_B_list, class_C_list, class_A_dict, class_B_dict, class_C_dict,GPANew = create_class_dicts()\n",
    "\n",
    "#Create a copy of our main dictionary. Just a reflex to protection.\n",
    "class_A_dict2 = class_A_dict.copy()\n",
    "class_B_dict2 = class_B_dict.copy()\n",
    "class_C_dict2 = class_C_dict.copy()\n",
    "\n",
    "\n",
    "#Grade is our categorical variable and we treat it like it is.\n",
    "class_list = [class_A_dict2,class_B_dict2,class_C_dict2]\n",
    "for class_dict in class_list:\n",
    "    for key, value in class_dict.items():\n",
    "        value['Grade'] = value['Grade'].astype('category').cat.codes\n",
    "        class_dict[key] = value\n",
    "        \n",
    "        \n",
    "        \n",
    "#converting train data:class A in to a non-duplicate, categorized and fitered dataframe form \n",
    "train_semestername_list_A = ['A2013New', 'A2014New','A2015New']\n",
    "train_semesters_list_A = [value for (key,value) in class_A_dict2.items() if key in train_semestername_list_A] \n",
    "a_semester_df = pd.concat(train_semesters_list_A,join = 'outer', keys = 'StudentID')\n",
    "a_semester_df = a_semester_df.reset_index().drop(['level_0', 'level_1'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns = {'Grade': 'Grade_A' , 'HW1': 'HW1_A', 'HW2' : 'HW2_A' , 'HW3':'HW3_A', 'MT1':'MT1_A', 'MT2':'MT2_A','MT3':'MT3_A','TOTAL' : 'TOTAL_A'})\n",
    "\n",
    "#converting train data:class B in to a non-duplicate, categorized and fitered dataframe form \n",
    "train_semestername_list_B = ['B2013New', 'B2014New','B2015New']\n",
    "train_semesters_list_B = [value for (key,value) in class_B_dict2.items() if key in train_semestername_list_B] \n",
    "b_semester_df = pd.concat(train_semesters_list_B,join = 'outer', keys = 'StudentID')\n",
    "b_semester_df = b_semester_df.reset_index().drop(['level_0', 'level_1'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns = {'Grade': 'Grade_B' , 'PRJ': 'PRJ_B', 'Q1' : 'Q1_B' , 'MT1':'MT1_B', 'MT2':'MT2_B','MT3':'MT3_B','TOTAL' : 'TOTAL_B'})\n",
    "\n",
    "#converting train data:class A in to a non-duplicate, categorized and fitered dataframe form \n",
    "train_semestername_list_C = ['C2013New', 'C2014New','C2015New']\n",
    "train_semesters_list_C = [value for (key,value) in class_C_dict2.items() if key in train_semestername_list_C] \n",
    "c_semester_df = pd.concat(train_semesters_list_C,join = 'outer', keys = 'StudentID')\n",
    "c_semester_df = c_semester_df.reset_index().drop(['level_0', 'level_1'],axis = 1).drop_duplicates(subset = 'StudentID', keep = 'last').rename(columns = {'Grade': 'Grade_C' , 'PRJ': 'PRJ_C', 'Q1' : 'Q1_C' , 'MT1':'MT1_C', 'MT2':'MT2_C','MT3':'MT3_C','TOTAL' : 'TOTAL_C'})\n",
    "\n",
    "\n",
    "#Lets categorize out GPA in to 4 brackets \n",
    "condlist = [GPANew['GPA']<=2.5,GPANew['GPA']<=3,GPANew['GPA']<=3.5, GPANew['GPA']<=4]\n",
    "choicelist = [1,2,3,4]\n",
    "GPANew['GPA'] = np.select(condlist,choicelist, default = 999 )\n",
    "GPANew = GPANew.drop('TotalCredits',axis = 1)\n",
    "\n",
    "#Merge our features data class A, B and C dataframes in to one on StudentID key\n",
    "#Filling NaN values with 1 is not a knowledge decision, I tried several possibilities, like 0, 999. Best solution is reached by 1\n",
    "#One important issue is applying inner join in last merge: if the student do not exist in GPANew, it not possible to assign an GPA bracket to her.\n",
    "full_data_df = pd.merge(GPANew, pd.merge(a_semester_df, pd.merge(c_semester_df, b_semester_df,how= 'outer', on = 'StudentID' ),how= 'outer', on = 'StudentID' ), how = 'inner', on = 'StudentID' ).fillna(1)\n",
    "\n",
    "#Set target array and features df\n",
    "df_feature = full_data_df.drop('GPA',axis=1)\n",
    "target = full_data_df['GPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDecisionTreeClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.54098361 0.57377049 0.50819672 0.61666667]\n",
      "Mean Accuracy Score - \u001b[4m0.5599043715846994\u001b[0m\n",
      "\u001b[1mBaggingClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.6557377  0.67213115 0.49180328 0.6       ]\n",
      "Mean Accuracy Score - \u001b[4m0.6049180327868853\u001b[0m\n",
      "\u001b[1mRandomForestClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.63934426 0.59016393 0.57377049 0.63333333]\n",
      "Mean Accuracy Score - \u001b[4m0.6091530054644809\u001b[0m\n",
      "\u001b[1mAdaBoostClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.63934426 0.60655738 0.50819672 0.23333333]\n",
      "Mean Accuracy Score - \u001b[4m0.49685792349726776\u001b[0m\n",
      "\u001b[1mGradientBoostingClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[0.73770492 0.59016393 0.50819672 0.63333333]\n",
      "Mean Accuracy Score - \u001b[4m0.6173497267759562\u001b[0m\n",
      " \n",
      "--------------------MSE Scores--------------------------\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[-0.73770492 -0.54098361 -0.86885246 -0.58333333]\n",
      "Mean Accuracy Score - \u001b[4m-0.6827185792349727\u001b[0m\n",
      "\u001b[1mBaggingClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[-0.54098361 -0.47540984 -0.6557377  -0.65      ]\n",
      "Mean Accuracy Score - \u001b[4m-0.5805327868852459\u001b[0m\n",
      "\u001b[1mRandomForestClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[-0.37704918 -0.59016393 -0.59016393 -0.58333333]\n",
      "Mean Accuracy Score - \u001b[4m-0.5351775956284153\u001b[0m\n",
      "\u001b[1mAdaBoostClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[-0.40983607 -0.59016393 -0.83606557 -0.96666667]\n",
      "Mean Accuracy Score - \u001b[4m-0.7006830601092896\u001b[0m\n",
      "\u001b[1mGradientBoostingClassifier\u001b[0m\n",
      "Accuracy Score of each fold\n",
      "[-0.45901639 -0.55737705 -0.54098361 -0.41666667]\n",
      "Mean Accuracy Score - \u001b[4m-0.4935109289617487\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#We are trying new classifiers in question 3 as a result of multiple inputs.\n",
    "#Q1 and Q2 have had single dimension features.So It was unnecessary to implement multiple classifiers.\n",
    "#define desired predictors\n",
    "clf = DecisionTreeClassifier()\n",
    "bgc = BaggingClassifier(base_estimator=clf, random_state=42)\n",
    "rfc = RandomForestClassifier()\n",
    "abc = AdaBoostClassifier(random_state=42)\n",
    "sgb = GradientBoostingClassifier( random_state=42)\n",
    "\n",
    "#predictors list\n",
    "classifier_list = [clf,bgc,rfc,abc,sgb]\n",
    "\n",
    "#Calculate mean cv scores and view accuracies for each fold\n",
    "classifier_name = []\n",
    "cv_score_list = []\n",
    "mean_cvs = []\n",
    "for i in classifier_list:\n",
    "    print('\\033[1m'+str(i)[0:str(i).find('(')]+'\\033[0m')\n",
    "    classifier_name.append(str(i)[0:str(i).find('(')])\n",
    "    cv_scores, mean_cv = lets_cross_validate(i, df_feature, target, cv = KFold(4, shuffle = True, random_state = 42), scoring = 'accuracy')\n",
    "    cv_score_list.append(cv_scores)\n",
    "    mean_cvs.append(mean_cv)\n",
    "#Calculate mean cv scores and view accuracies for each fold\n",
    "classifier_name = []\n",
    "cv_score_list = []\n",
    "mean_cvs = []\n",
    "print(' ')\n",
    "print('--------------------MSE Scores--------------------------')\n",
    "print(' ')\n",
    "for i in classifier_list:\n",
    "    print('\\033[1m'+str(i)[0:str(i).find('(')]+'\\033[0m')\n",
    "    classifier_name.append(str(i)[0:str(i).find('(')])\n",
    "    cv_scores, mean_cv = lets_cross_validate(i, df_feature, target, cv = KFold(4, shuffle = True, random_state = 42), scoring = 'neg_mean_squared_error')\n",
    "    cv_score_list.append(cv_scores)\n",
    "    mean_cvs.append(mean_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best 3 classifiers, accuracy score, MSE:\n",
    " - BaggingClassifier = 0.6419753086419753 ,0.5061728395061729\n",
    " - RandomForestClassifier = 0.6172839506172839 ,0.5720164609053497\n",
    " - GradientBoostingClassifier = 0.6008230452674898, 0.5720164609053497\n",
    "\n",
    "Possible to say, higher the models Accuracy score , lower the MSE score .\n",
    "So we choose Bagging classifier and we will implement hyper parameter tuning on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyper-paraneter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "[[21  2  0  0]\n",
      " [ 2  8  0  0]\n",
      " [ 3  2  8  2]\n",
      " [ 0  0  1  0]]\n",
      "0.7551020408163265\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df_feature, target, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "parameters = {\n",
    "              'max_features': ['auto', 'sqrt','log2', None],\n",
    "              'min_samples_leaf': [8, 12],\n",
    "              'min_samples_split': [10, 14],\n",
    "              'max_depth': list(np.linspace(5, 30, 2, dtype = int)) + [None],\n",
    "              'learning_rate': [0.05,0.1,0.2,0.3],\n",
    "              'n_estimators' : list(np.linspace(5, 100, 5, dtype = int)), \n",
    "             }\n",
    "sgb = GradientBoostingClassifier( random_state=42)\n",
    "model = RandomizedSearchCV(estimator = sgb, param_distributions = parameters, n_iter = 20, \n",
    "                               cv = 4, verbose= 5, random_state= 42, n_jobs = -1)\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "\n",
    "print(\"Random\")\n",
    "predictionforest = model.best_estimator_.predict(test_x)\n",
    "print(confusion_matrix(test_y,predictionforest))\n",
    "print(metrics.accuracy_score(test_y,predictionforest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  2  0  0]\n",
      " [ 2  8  0  0]\n",
      " [ 3  2  8  2]\n",
      " [ 0  0  1  0]]\n",
      "0.7551020408163265\n"
     ]
    }
   ],
   "source": [
    "#model.get_params\n",
    "final_sgb = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "              max_features=None, max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "\n",
    "final_sgb.fit(train_x,train_y)\n",
    "predictionforest = model.best_estimator_.predict(test_x)\n",
    "print(confusion_matrix(test_y,predictionforest))\n",
    "print(metrics.accuracy_score(test_y,predictionforest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
